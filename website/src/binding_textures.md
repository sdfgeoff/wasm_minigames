# Binding Textures

Being able to run a shader is one thing, but a lot of the time we also need
to load in image textures. The way Mozilla suggests in their tutorials is to
use a XMLHttpRequest to fetch the image. However, because we're in a compiled
language we should be able to compile the image into the WASM blob. This isn't
necessarily always a good solution, but for small games it ensures that the
texture will be available at the same time as the WASM is loaded.

[`gl.texImage2D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texImage2D)
is the function that is used to actually bind the texture. It can take input
in a whole bunch of forms, but most of these forms require uncompressed image data
or an HTML element. Rather than decompress the image in Rust, or decompress it
before including in the binary, we can get the browser to do it for us - we just
need some way to tell the browser to use data from our WASM blob as an image.

Turns out there's some hoops to jump through:

1. Put the bytes in the binary
2. Convert the bytes into a Javascript Uint8Array
3. Create a "Blob" object from our Uint8Array
4. Create a URL so that html can "find" the image
4. Create a HTMLImageElement, and use the url pointing at the blob as the source

Loading the HTMLImageELement is asynchronus, so outside all of that we need
to:

1. Create a blank texture
2. Kick off the loading
3. Substitute in the texture when it's done.

First up lets create a shader that uses a texture:

```glsl
{{#include ./games/binding_textures/src/resources/shader.frag}}
```
The `vec2 uv = screen_pos.xy * 0.5 - 0.5` is because the `screen_pos` variable goes
from -1 to 1, but texture coordinates in the `texture` function go from 0 to 1.

And let's create a (blank) texture and pass it into the shader program

```
// Create texture
let texture = gl.create_texture().ok_or(TextureError::CreateTextureError)?;

// Tell webgl what texture to operate on
// (note the next function has no texture parameter)
gl.bind_texture(WebGl2RenderingContext::TEXTURE_2D, Some(&texture));

// Give our texture a default color
gl.tex_image_2d_with_i32_and_i32_and_i32_and_format_and_type_and_opt_u8_array(
    WebGl2RenderingContext::TEXTURE_2D,
    0, // Level
    WebGl2RenderingContext::RGBA as i32, // Format
    1, // width
    1, // height
    0, // border
    WebGl2RenderingContext::RGBA, // source format
    WebGl2RenderingContext::UNSIGNED_BYTE, // type
    Some(&[255,0,255,255]) // pixels
);


<< snip >>
Note that &self.image_texture is the "texture" in the previous snippet


// Tell WebGL we want to affect texture unit 0
gl.active_texture(WebGl2RenderingContext::TEXTURE0);

// Tell Webgl we want to operate on our texture
gl.bind_texture(WebGl2RenderingContext::TEXTURE_2D, Some(&self.image_texture));

// Connect our uniform in the shader to teh 
gl.uniform1i(self.uniform_image_texture.as_ref(), 0);
```

If we had the uncompressed image data we could fork it into the call to
`tex_image_2d_with_i32_and_i32_and_i32_and_format_and_type_and_opt_u8_array`
(that is one long autogenerated function name!). However we need to uncompress
it as mentioned earlier.

Probably easiest just to show the code:
```rust
{{#include ./games/binding_textures/src/texture.rs}}
```
As you can see, it goes through all the stages of passing the image into a
HTMLImageElement and setting up a callback so that when it's uncompressed, it
gets loaded into the GPU.

It's worth mentioning that although we use the `include_bytes!()` macro here,
it is trivial to remove that and instead use the `set_src` of the `image_element`
to make this into a function that loads a texture from the web rather than
from the binary. This would be useful if you have lots of textures and need
to stream them in dynamically, but for the sorts of games I plan to make it
isn't really needed.


The end result:

<canvas id="binding_textures"></canvas>
